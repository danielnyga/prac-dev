\documentclass[10pt,a4paper]{article}
%\usepackage[italian]{babel}
\usepackage{fullpage}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}

\usepackage[T1]{fontenc} 
%\usepackage[utf8]{inputenc} 
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{color}
%\usepackage{minted}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{%
  \parbox{\textwidth}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}\vskip-4pt}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{frame=lrb,xleftmargin=\fboxsep,xrightmargin=-\fboxsep,language=[LaTeX]{TeX},columns=flexible}
\renewcommand{\lstlistingname}{Example}


\newcommand{\dialog}[3][(1)]{
  \textit{{(#1)} #2: {\color{Bittersweet} ``#3``}}\\}
  
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=Gray,
    urlcolor=black
}

\usepackage{multicol}


%\usepackage{cite}

%\usepackage{natbib}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\makeindex

\begin{document}


\begin{center}
\large{{Technische Universitaet Muenchen} - M.Sc. Informatics }\\ \Large{ InterDisziplinaeres Project(IDP):\\ \textbf{Probabilistic Robot Action Cores - uncertainty verbalization for semantic disambiguation}
}\\
\normalsize{{Institute of Automatic Control Engineering}} \\
\normalsize{{Department of Electrical Engineering and Information Technology}}\\

\small{{Examiner: Prof. Joerg Conradt}} - \small{{Advisor: Daniel Nyga, M.Sc.}}\\
\normalsize{{Student: Nicholas H. Kirk - mat. 03624396}} \\

\end{center}

\vspace{2 mm}
% \begin{abstract}
% The project focuses on ambiguity clarification the 
% context of task instructing for robotic assistants
% in everyday tasks.
% The summary then shows the accomplishments 
% The abstract should summarize the contents of the paper
% using at least 70 and at most 150 words. It will be set in 9-point
% font size and be inset 1.0 cm from the right and left margins.
% There will be two blank lines before and after the Abstract. \dots
% \end{abstract}

\begin{center}
 \textbf{keywords}: cognitive architectures, computational linguistics, robotics.
\end{center}
\vspace{2 mm}

\begin{multicols}{2}
\tableofcontents

%\addcontentsline{toc}{chapter}{Contents}
%\listoffigures
%\addcontentsline{toc}{chapter}{List of Figures}
%\listoftables
%\addcontentsline{toc}{chapter}{List of Tables}
\end{multicols}

\section{introduction}
\subsection{to the project}
A more detailed definition of the preexistent background is given in the scope definition (for a high level overview) and in Nyga12actioncore quote (for a technical deep dive).
\subsection{to the document}
Given the interdisciplinarity of the topic (i.e. cognition, natural language processing, statistical relational learning) this document is intended to describe the undergone research process as close as possible, both from a technical and ideation standpoint, by following the incremental progress of the project.\\
An overview of the contribution to the background will be given, to then progressively shift towards more technical and linguistical aspects of the implementation.

%\begin{minted}{c}

%\end{minted}

%\begin{minted}{python}
%def boring(args = None):
%pass
%\end{minted}

\section{preliminary understanding}
\paragraph{abstraction level}
Probabilistic Robot Action Cores are an everyday-task oriented formalization that abstracts from the Markov Logic Network formulas at a lower level.
We therefore focus on the verbalization of uncertain elements in the PRAC serialization. The expanded MLN statements are not of direct interest for the scope, since their verbalization
would not be of interest and scarcely intelligible.

%Let us identify two different verbalization modes:
%\begin{enumerate}
% \item[\textbf{verbose}]: Statement of the full understanding and not understanding of the NLI (complete PRAC verbalization). 
% \item[\textbf{non verbose}]: Statement of the not understood NLI part
%\end{enumerate}
%This is because in case of high ambiguity, the human might want to verify the full understanding of the robot assistant.
%Or robots assistants might want to clarify some aspects between themselves.
%Verbalization is dependent on the specific NLI instance and context-related.
%After a disambiguation, if the clarification is generalizable, this can be used as ground truth for other processes.
\subsection{interaction overview}
Let us lay the ground for our interaction analysis:
\begin{center} %Abstraction interaction overview
\fbox {
    \parbox{100 mm}{
    \begin{flushright}
{\color{Bittersweet} \huge \text{Human \textrightarrow Robot}} \hspace{1 mm}  { \Large \textit{instructing} \hspace{2 mm}}\\     
    \end{flushright}
    \[
\textit{{\Large 0} \dots \text{\huge n }}
\begin{cases} 

{\color{Bittersweet} \huge \text{Robot \textrightarrow Human}} & { \Large \textit{querying}}\\
{\color{Bittersweet} \huge \text{Human \textrightarrow Robot}} & { \Large \textit{clarifying}}\\

\end{cases}
\]
    }
}\\

\vspace{1 mm}
\text{Abstract interaction overview}
\end{center}

More specifically:
\begin{enumerate}
 \item Human \textrightarrow Robot: NaturalLanguageInstruction (English language) 
 \item Robot\textrightarrow Human: AmbiguityResolutionRequest (defined subset of the English language $\Leftrightarrow$ with
PRAC MLN)
 \item Human\textrightarrow Robot: NaturalLanguageDisambiguation (English Language)
\end{enumerate}

\subsection{linguistic concerns}

We now analyse the previously stated points, highlighting possible concerns strictly related to the interaction:
\begin{enumerate}
 \item Normally in imperative form. In English we have more ambiguity given that imperative form can
lead to loss of correct use of grammar (in particular when the NLI is long), but we have lower parsing
complexity considering there is no verb conjugation (the infinite form is used).
 \item Our cognitive system will verbalize a sentence in which asks for clarifications regarding a set of
aspects related to the task, using the lexicon learnt in (1), with which the relationships of the PRAC has
been built.
 \item The human will provide an explanation, possibly providing solutions to all ambiguity concerns of
the robot, in a non-imperative and maybe hypotactical manner (with subordinate sentences).
\end{enumerate}

\paragraph{vocabulary variation}
Mapping between lexicon of (1), (2) and (3) can be complex ( e.g. First it is instructed as ``X
needs Y``, then ``X requires Y and Z``). Between (1) and (2) is trivial, but the correlation with
(3) is not. Further questioning could hypothetically lead to loops of lexicon clarification.
The system should foresee these possible changes and verify synonyms when importing.

\paragraph{anaphora resolution}
Correct anaphora resolution of informal sentences (e.g.''The pancake needs flower, it can be found on the shelf``, it refers
to flower).

\subsection{possible disambiguation classes}
In this section we try to identify what kind of clarification could be necessary are possible or likely, formalizing a list of possible clarification classes that we might need to verbalize.

\paragraph{Taxonomy clarification}
Classification of an object that is useful in the scope, clarifying the higher class.

\dialog[1]{Querying}{What is X?}
\dialog[2]{Clarifying}{X is a type of flower.}

%\paragraph{Instrument clarification}
%Replies to the question ''via what mean(s)?``

%\paragraph{Location clarification} %stato in luogo
%replies to the question ''from/to where?``
%\paragraph{}%moto da/a luogo

\paragraph{Temporal clarification}
Most frequently a time instruction is ambiguous. A post processing phase will be necessary to classify the residual ambiguity (i.e. ''for dinner``).

\dialog[1]{Instructing}{Flip the pancake in a while.}
\dialog[2]{Querying}{When should the pancake be flipped?}

\paragraph{Anaphora resolution}
References to previous sentences could be present in an anaphoric form.\\

\dialog[1]{Clarifying}{Cook it now.}
\dialog[2]{Querying}{What is 'it'?}

\paragraph{Context adaptation}
The NLI could ask for something that is not feasible in that context (e.g. the object that should be used is either not present or not useful for the task).\\

\dialog[1]{Instructing}{Flip the pancake.}
{(context: no spatulas or similars around)}\\
\dialog[2]{Querying}{What can flip the pancake?}

\dialog[1]{Instructing}{Flip the pancake with a screwdriver.}
(context: spatula around, presence of screwdriver irrelevant)\\
\dialog[2]{Querying}{The spatula can be used?}

%\dialog[1]{}{Ã—}
%TODO: revise the following and rewrite it
%\textit{(1) Instructing: {\color{Bittersweet} ''Flip the pancake with a screwdriver.``}}\\
%(context: spatula around, presence of screwdriver irrelevant)\\
%\textit{(2) Querying: {\color{Bittersweet} ''What can flip the pancake?``}}\\

%\textit{(1) Instructing: {\color{Bittersweet} ''Flip the pancake with a spatula.``}}\\
%(context: no spatula around)\\
%\textit{(2) Querying: {\color{Bittersweet} ''What can flip the pancake?``}}\\

%With what can the pancake be flipped?

\paragraph{Identity clarification}
Another when multiple instances of artificial assistants are present - it could then be useful to disambiguate who will accomplish a specific task.
''Who is the robot that should cook the pancake?``

\dialog[1]{Instructing}{Flip the pancake.}
(context: multiple assistants)\\
\dialog[2]{Querying}{Who should flip the pancake?}


\section{reuse of state-of-the-art technologies}

\subsection{Controlled Language - ACE}

% Norbert E. Fuchs, Kaarel Kaljurand, Gerold Schneider (2006). "Attempto Controlled English Meets the Challenges of Knowledge Representation, Reasoning, Interoperability and User Interfaces" (PDF). FLAIRS 2006.

Attempto Controlled English (ACE) is a controlled natural language, i.e. a subset 
of standard English with a restricted syntax and a restricted semantics described 
by a small set of construction and interpretation rules.[1]

ACE can serve as knowledge representation, specification, and query language, and 
in our context it is used as a linguistic notation to interface humans and peer 
robotic assistants, without ambiguity - Though ACE appears perfectly natural and 
indistinguishable from English, it is in fact a formal language.

\paragraph{ACE limitations} 

\begin{itemize}
 \item[] \textbf{workaround to personal pronouns} since these in first person singular 
 are purpusely not implemented in ACE and the other forms can incur in ambiguous anaphora 
 refences, we will use the passive form, even if this brings a partial loss of semantics 
 (e.g.\textit{''I will boil the water`` \textrightarrow ''The water will be boiled.``}).
\end{itemize}

\subsection{Metalanguage: Discourse Representation Structures (DRS)} 

Discourse representation structures (DRS) represent a hearer's mental representation 
of a discourse as it unfolds over time. There are two critical components to a DRS:

\begin{itemize}
 \item A set of DRS referents representing entities which are under discussion.
 \item A set of DRS conditions representing information that has been given about discourse 
 referents.
\end{itemize}
Example:\\
\textbf{(1) {\color{Bittersweet} A robot flips a pancake.}}\\
The DRS of \textbf{(1)} can be notated as \textbf{(2)} below:\\
\textbf{(2) {\color{Bittersweet} [x,y: robot(x), pancake(y), flips(x,y)]}}\\

In which x,y are discourse referents, and the remaining statements are discourse conditions.\\
To show sequentiality, we add the following sentence to the discourse.\\
\textbf{(3) {\color{Bittersweet} A robot flips a pancake. He burns it.}}\\
\textbf{(4) {\color{Bittersweet} [x, y: robot(x), pancake(y), flips(x,y), burns(x,y)]}}\\

We shall make use of DRS as the verbalizer's intermediate representation, 
specifically the DRS implementation of the Attempto Project.

\paragraph{Why not OWL ontologies?} OWL ontologies are a defacto standard and currently 
standard drafts of many versions are under examination, however we observe the following 
theoretical limitations:

\begin{itemize}
 \item OWL is not easily human-readable, and a verbalization would require postprocessing.
 \item OWL cannot express modal formulations (these being likelihood, ability, permission,
 and obligation), since these imply possibility and not certainty, and this conflicts directly 
 with the concept of a non-probabilistic ontology. 
 \item OWL cannot express questions. This can be overid by mild postprocessing on a question 
 that treats a query word (e.g. when, what, who) as a noun.
\end{itemize}

\subsection{reasons behind the technology adoptions}

A preexistent language framework able to verbalize relationships between entities 
is necessary given its ability to conjugate verbs, resolve references, set 
appropriate gender and plurality declinations. The use of a specific implementation 
of Controlled Language is desirable for compatibility between future ontologies.

\section{scenario development (technical)}

The process loops $n$ times to clarify ambiguity, until this is reduced to a minimal preestablished level ($n$ can be bounded for hindrance reasons i.e. excessive questioning).

\begin{center} %Technical interaction overview
\fbox {
    \parbox{110 mm}{
        \begin{flushright}
{\color{Blue} \LARGE \text{NLI \textrightarrow PRAC}} \hspace{1 mm}  { \Large \textit{instructing} \hspace{5 mm}}\\     
    \end{flushright}
%    \raggedright
\[
\textit{{\Large 0} \dots \text{\huge n }}
\begin{cases} 

{\color{Blue} \LARGE \text{PRAC \textrightarrow DRS \textrightarrow ACE}} & { \Large \textit{querying}}\\
{\color{Blue} \LARGE \text{NLD \textrightarrow PRAC inf.merge}} & { \Large \textit{clarifying}}\\

\end{cases}
\]
    }
}\\
\vspace{1 mm}
\text{High-level technical overview}
\end{center}

Technical modules required: 
\begin{enumerate}
 \item Prioritization module and assessment of probabilities [RNF.tech.1]
 \item DRS constructor module [RNF.tech.2]
 \item DRS to ACE module [RNF.tech3]
 \item Core to call the prioritization module, consult config files (global and local), 
 verbalize (i.e. call the DRS constructor, call the DRS>ACE module).
\end{enumerate}

%  Approx verbalization:
%  Not verbose.: direct questioning
%  verbose: e.g. The pan has to be filled with the THEME that is from the SOURCE.  
%  objective: the human understands if the robot got the correct actioncore. 
%  In case of questioning, the robot refers to the last session that he closes each time he is satisfied.

\paragraph{importance of syntactic relationships}
For each specific instance there is a set of syntactic relationships for each 
action role, information that is necessary for the language generation of 
the questions.

\paragraph{}
Upon construction of a specific PRAC definition, a Controlled Language sentence 
will be defined as one of their possible syntactic mappings. This is possible 
%TODO:
This structure mapping is partially obtainable from the parsing phase done via 
the 'stanford parser' 3rd party software module. The rest of the structure is 
related to the syntactic roles of the understated PRAC part.

\paragraph{Why not formalize the NLI in CL?}
The act of mapping the syntactic analysis of the hole NLI and the understated part 
to DRS atoms is equivalent to a full logic formalization of such natural language 
statements (bringing the NLI from natural to deterministic), work that is to-date 
considered complex and postponed to future research.

\subsection{action role querying}

Once these features are indentified, preestablished DRS templates can be used as metalevel for the generation.


We now examine the specific case in which one or more of the action roles have not been assigned.
%\subsection{PRAC ambiguity to DRS mapping}
%From tests (examples below) it is clear that the DRSs of any of our questions 
%can be generated automatically according to their related disambiguation class (being these
%query for temporal, instrumental matters and so on) - any multiple query can be generated 
%by compounding the single queries in one DRS, as demonstrated previously.
%\subsection{Cases to DRS mapping}
%The issue is to identify the disambiguation classes of the uncertain PRAC fields.
%Empirically, this should be feasible thanks to the use of the wordnet field 'Glosses', recognising 
%terms such as 'tool' in the description.

To do so, we have to retrieve the syntactic role(s) of the badly parsed action role(s) together with other lemmas 
that share 'close' syntactic relationships.
From that we proceed in generating the question querying the concept and defining the 'close' context.

\subsection{answer integration}

\subsection{badly inferred components}
We now examine the case in which some understated aspects were not inferrable with confidence.

\newpage
\appendix
\subsection{verbalization example}
{\small
\begin{lstlisting}[language=c,label=firstlook,caption=serialized PRAC of the verb 'Filling']
action_core: Filling
inherits_from: ContainerFocusedPlacing
examples:
    - The GOAL has to be filled with the THEME that is from the SOURCE.

action_roles:
    - Goal:
        - definition: A goal is an area that has to be filled.
    - Theme:
        - definition: The Theme is the physical object 
          substance which changes location. 
    - Source:
        - definition: 
\end{lstlisting}
\textbf{We now analyse a specific instance, making use of the shown PRAC}:\\

\parbox[c]{800px}{
NaturalLanguageInstruction: ''The pan has to be filled with the OliveOil that is from the Cupboard.``\\
In the following we exercise the questioning for the GOAL, THEME and SOURCE respectively:	
}

\begin{lstlisting}[language=HTML,label=firstlook,caption=ACE questions and resulting DRS]

(1) What has to be filled with the OliveOil?
(2) The pan has to be filled with what?
(3) The OliveOil is from what? 

DRS = 
[]
   QUESTION
   [A]
   query(A,what)-1/1
      MUST
      [B,C]
      property(B,filled,pos)-1/7
      predicate(C,be,A,B)-1/
      modifier_pp(C,with,named(OliveOil))-1/8
   QUESTION
   [D]
   object(D,pan,countable,na,eq,1)-2/4
      MUST
      [E,F,G]
      query(E,what)-2/12
      property(F,filled,pos)-2/10
      predicate(G,be,D,F)-2/
      modifier_pp(G,with,E)-2/11
   QUESTION
   [H,I]
   query(H,what)-3/5
   predicate(I,be,named(OliveOil))-3/3
   modifier_pp(I,from,H)-3/4

\end{lstlisting}
}


\newpage



%Understanding paraphrase = [[It is necessary that THEME is 
%from SOURCE and that GOAL is a:filled with THEME.]]

%\subsection{DRS equivalence}
%In the current implementation of DRS ACE, the following:

%(1) \textbf{\color{Bittersweet}  Pr2 flips what?}\\
%(2) \textbf{\color{Bittersweet}  what does Pr2 flip?}\\

%Are translated in the same DRS, hence the impossibility to translate back in one of the two forms, namely (2).

%Furthermore all aspects of the PRAC instance should be ready for verbalization whenever asked from the instructor.
%DRS enables us to 

% 
% action_core: Flipping
% definition: An Agent causes a Theme to move with respect to a FixedLocation, generally with a certain Periodicity, without undergoing unbounded translational motion or significant alteration of configuration/shape.
% inherits_from: CauseMotion
% Examples:
%       - The theme has to be flipped from FixedLocation with the Instrument.
%       - The pancake has to be flipped from the working table with the spatula.
%       
% action_roles:
%     - Theme:
%         - definition: A physical entity that is participating in non-translational motion.
%     - FixedLocation:
%         - definition: The point or set of points that define the limits of motion for the Theme. For spinning motions, it is the axis, for vibrating it is a boundary, for swinging it is a point. 
%         - range: LocativeRelation
%     - Instrument: An entity that is used to perform the flipping action.
% action_verbs:
%     - flip: flip.v.08 
%     
%     Verbalization:
%     
%     Understanding: 
%     <The theme has to be flipped from FixedLocation with the Instrument.>
% 
%     Querying: 
%     <THEME is missing:
%     What has to be flipped from FixedLocation with the Instrument?>
% 
%     <FixedLocation is missing:
%     the pancake has to be flipped from what?>
%     
%     <Instrument:
%     The theme has to be flipped with what?
%     (turn upside down, or throw so as to reverse)>

%     Context:
%     Rule working.
%     
%     (gestire le nidificazioni)
%     
%     Categories:
%     
%     Temporal
%     Instrumental
%     
%  \]   

%\bibliography{ref}{}
%\bibliographystyle{plain}
\end{document}
